{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZpL92dyKqQhr"
      },
      "outputs": [],
      "source": [
        "# @title Importing dependencies\n",
        "import numpy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1Ov-jmgF8Wn",
        "outputId": "0347e74d-1750-47b7-c3c6-2b0e65c10e04"
      },
      "outputs": [],
      "source": [
        "# @title Downloading MNIST dataset\n",
        "mnist_train = torchvision.datasets.MNIST('/home/stuti/fods/files/', train=True, download=True,\n",
        "                            transform=torchvision.transforms.Compose([\n",
        "                                torchvision.transforms.ToTensor()\n",
        "                            ]))\n",
        "mnist_test = torchvision.datasets.MNIST('/home/stuti/fods/files/', train=False, download=True,\n",
        "                            transform=torchvision.transforms.Compose([\n",
        "                                torchvision.transforms.ToTensor()\n",
        "                            ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Sj4JnUYF9YD"
      },
      "outputs": [],
      "source": [
        "# # @title Binarise MNIST data\n",
        "# def binarise_mnist(mnist):\n",
        "#     mnist_bin = []\n",
        "#     for img, label in mnist:\n",
        "#         mnist_bin.append((torch.where(img < 0.5, 0.0, 1.0), label))\n",
        "#     return mnist_bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mI7g-BGGF-fN"
      },
      "outputs": [],
      "source": [
        "# X_train = binarise_mnist(mnist_train)\n",
        "# X_test = binarise_mnist(mnist_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vAnk-eOIGAWM"
      },
      "outputs": [],
      "source": [
        "class CroppedConvolution2D(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, padding: tuple):\n",
        "        super(CroppedConvolution2D, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_height, self.kernel_width = kernel_size\n",
        "        self.padding = padding\n",
        "        self.conv = nn.Conv2d(self.in_channels, self.out_channels, kernel_size, padding=self.padding)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.conv(X)\n",
        "        out = X[:, :, 1:-self.kernel_height, :]\n",
        "        up_shifted_out = X[:, :, :-self.kernel_height-1, :]\n",
        "        return out, up_shifted_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Cr6bRjqdGDpi"
      },
      "outputs": [],
      "source": [
        "class MaskedConvolution2D(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, padding: tuple, mask_type: str):\n",
        "        super(MaskedConvolution2D, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_height, self.kernel_width = kernel_size\n",
        "        self.padding = padding\n",
        "        self.mask_type = mask_type\n",
        "        self.conv = nn.Conv2d(self.in_channels, self.out_channels, kernel_size, padding=self.padding)\n",
        "        self.create_mask()\n",
        "\n",
        "    def create_mask(self):\n",
        "        mask = torch.ones(self.kernel_height, self.kernel_width)\n",
        "        mask[self.kernel_height // 2, self.kernel_width // 2:] = 0\n",
        "        mask[self.kernel_height // 2 + 1:, :] = 0\n",
        "        if self.mask_type == 'B':\n",
        "            mask[self.kernel_height // 2, self.kernel_width // 2] = 1\n",
        "        self.register_buffer('mask', mask)\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.conv.weight.data = self.conv.weight.data * self.mask\n",
        "        return self.conv(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J9R87gFXGE52"
      },
      "outputs": [],
      "source": [
        "class CausalBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int):\n",
        "        super(CausalBlock, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "        self.vertical_fc = nn.Conv2d(in_channels=in_channels,\n",
        "                                     out_channels=2*out_channels,\n",
        "                                     kernel_size=(1, 1))\n",
        "\n",
        "        self.vertical_conv = CroppedConvolution2D(in_channels=in_channels,\n",
        "                                                  out_channels=2*out_channels,\n",
        "                                                  kernel_size=(kernel_size // 2 + 1, kernel_size),\n",
        "                                                  padding=(kernel_size // 2 + 1, kernel_size // 2))\n",
        "\n",
        "        self.vertical_to_horizontal = nn.Conv2d(in_channels=2*out_channels,\n",
        "                                                out_channels=2*out_channels,\n",
        "                                                kernel_size=(1, 1))\n",
        "\n",
        "        self.horizontal_conv = MaskedConvolution2D(in_channels=in_channels,\n",
        "                                                   out_channels=2*out_channels,\n",
        "                                                   kernel_size=(1, kernel_size),\n",
        "                                                   padding=(0, kernel_size // 2),\n",
        "                                                   mask_type='A')\n",
        "\n",
        "        self.horizontal_fc = MaskedConvolution2D(in_channels=out_channels,\n",
        "                                                 out_channels=out_channels,\n",
        "                                                 kernel_size=(1, 1),\n",
        "                                                 padding=(0, 0),\n",
        "                                                 mask_type='A')\n",
        "\n",
        "    def forward(self, X):\n",
        "        out_vertical_fc = self.vertical_fc(X)\n",
        "        out_vertical_conv, up_shifted_out_vertical_conv = self.vertical_conv(X)\n",
        "        out_vertical_to_horizontal = self.vertical_to_horizontal(up_shifted_out_vertical_conv)\n",
        "        out_vertical = out_vertical_fc + out_vertical_conv\n",
        "        out_vertical_tanh, out_vertical_sigmoid = torch.split(out_vertical, self.out_channels, dim=1)\n",
        "        out_vertical = torch.tanh(out_vertical_tanh) * torch.sigmoid(out_vertical_sigmoid)\n",
        "\n",
        "        out_horizontal_conv = self.horizontal_conv(X)\n",
        "        out_horizontal = out_horizontal_conv + out_vertical_to_horizontal\n",
        "        out_horizontal_tanh, out_horizontal_sigmoid = torch.split(out_horizontal, self.out_channels, dim=1)\n",
        "        out_horizontal = torch.tanh(out_horizontal_tanh) * torch.sigmoid(out_horizontal_sigmoid)\n",
        "        out_horizontal = self.horizontal_fc(out_horizontal)\n",
        "\n",
        "        return out_vertical, out_horizontal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d7bN7vumGGQq"
      },
      "outputs": [],
      "source": [
        "class GatedBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, latent_dim: int=16):\n",
        "        super(GatedBlock, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        self.vertical_fc = nn.Conv2d(in_channels=in_channels,\n",
        "                                     out_channels=2*out_channels,\n",
        "                                     kernel_size=(1, 1))\n",
        "\n",
        "        self.vertical_to_horizontal = MaskedConvolution2D(in_channels=2*out_channels,\n",
        "                                                          out_channels=2*out_channels,\n",
        "                                                          kernel_size=(1, 1),\n",
        "                                                          padding=(0, 0),\n",
        "                                                          mask_type='B')\n",
        "\n",
        "        self.vertical_conv = CroppedConvolution2D(in_channels=in_channels,\n",
        "                                                  out_channels=2*out_channels,\n",
        "                                                  kernel_size=(kernel_size // 2 + 1, kernel_size),\n",
        "                                                  padding=(kernel_size // 2 + 1, kernel_size // 2))\n",
        "\n",
        "        self.horizontal_conv = MaskedConvolution2D(in_channels=in_channels,\n",
        "                                                   out_channels=2*out_channels,\n",
        "                                                   kernel_size=(1, kernel_size),\n",
        "                                                   padding=(0, kernel_size // 2),\n",
        "                                                   mask_type='B')\n",
        "\n",
        "        self.horizontal_fc = MaskedConvolution2D(in_channels=out_channels,\n",
        "                                                 out_channels=out_channels,\n",
        "                                                 kernel_size=(1, 1),\n",
        "                                                 padding=(0, 0),\n",
        "                                                 mask_type='B')\n",
        "\n",
        "        self.horizontal_skip = MaskedConvolution2D(in_channels=out_channels,\n",
        "                                                 out_channels=out_channels,\n",
        "                                                 kernel_size=(1, 1),\n",
        "                                                 padding=(0, 0),\n",
        "                                                 mask_type='B')\n",
        "\n",
        "        self.latent_embedding = nn.Linear(in_features=latent_dim, out_features=2*out_channels)\n",
        "\n",
        "    def forward(self, X):\n",
        "        in_vertical, in_horizontal, latent, skip = X['in_vertical'], X['in_horizontal'], X['latent'], X['skip']\n",
        "        latent_embedding = self.latent_embedding(latent).unsqueeze(2).unsqueeze(3)\n",
        "\n",
        "        out_vertical_fc = self.vertical_fc(in_vertical)\n",
        "        out_vertical_conv, up_shifted_out_vertical_conv = self.vertical_conv(in_vertical)\n",
        "        out_vertical_to_horizontal = self.vertical_to_horizontal(up_shifted_out_vertical_conv)\n",
        "        out_vertical = out_vertical_fc + out_vertical_conv + latent_embedding\n",
        "        out_vertical_tanh, out_vertical_sigmoid = torch.split(out_vertical, self.out_channels, dim=1)\n",
        "        out_vertical = torch.tanh(out_vertical_tanh) * torch.sigmoid(out_vertical_sigmoid)\n",
        "        out_vertical += in_vertical\n",
        "\n",
        "        out_horizontal_conv = self.horizontal_conv(in_horizontal)\n",
        "        out_horizontal = out_horizontal_conv + out_vertical_to_horizontal + latent_embedding\n",
        "        out_horizontal_tanh, out_horizontal_sigmoid = torch.split(out_horizontal, self.out_channels, dim=1)\n",
        "        out_horizontal = torch.tanh(out_horizontal_tanh) * torch.sigmoid(out_horizontal_sigmoid)\n",
        "        skip += self.horizontal_skip(out_horizontal)\n",
        "        out_horizontal = self.horizontal_fc(out_horizontal)\n",
        "        out_horizontal += in_horizontal\n",
        "\n",
        "        return {'in_vertical': out_vertical,\n",
        "                'in_horizontal': out_horizontal,\n",
        "                'latent': latent,\n",
        "                'skip': skip}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hcoa5y3jPnfG"
      },
      "outputs": [],
      "source": [
        "class ConditionalGate(nn.Module):\n",
        "    def __init__(self, latent_dim: int, out_channels: int=32):\n",
        "        super(ConditionalGate, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.latent_embedding_tanh = nn.Linear(in_features=latent_dim, out_features=out_channels)\n",
        "        self.latent_embedding_sigmoid = nn.Linear(in_features=latent_dim, out_features=out_channels)\n",
        "\n",
        "    def forward(self, X, latent_var):\n",
        "        out_tanh, out_sigmoid = torch.split(X, self.out_channels, dim=1)\n",
        "        out_tanh = out_tanh + self.latent_embedding_tanh(latent_var).unsqueeze(2).unsqueeze(3)\n",
        "        out_sigmoid = out_sigmoid + self.latent_embedding_sigmoid(latent_var).unsqueeze(2).unsqueeze(3)\n",
        "        out = torch.tanh(out_tanh) * torch.sigmoid(out_sigmoid)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s8ce7elsGI7c"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels: int, latent_dim: int):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, stride=1, padding='same'))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding='same'))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.ZeroPad2d((0, 1, 0,1)))  # Pad 7x7 feature maps to 8x8\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding='same'))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1))\n",
        "        layers.append(nn.ReLU())\n",
        "        for _ in range(3):\n",
        "            layers.append(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding='same'))\n",
        "            layers.append(nn.ReLU())\n",
        "        layers.append(nn.Flatten())\n",
        "        layers.append(nn.Linear(in_features=1024, out_features=2*latent_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def reparameterise(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.net(X)\n",
        "        mu, logvar = torch.split(out, self.latent_dim, dim=1)\n",
        "        z = self.reparameterise(mu, logvar)\n",
        "        return mu, logvar, z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2qwf5U_Jz7L"
      },
      "outputs": [],
      "source": [
        "# class Decoder(nn.Module):\n",
        "#     def __init__(self, latent_dim: int, gated_blocks: int):\n",
        "#         super(Decoder, self).__init__()\n",
        "#         self.latent_dim = latent_dim\n",
        "\n",
        "#         self.fc = nn.Linear(in_channels=latent_dim, out_channels=4*4*64)\n",
        "#         self.conv_1 = nn.Sequential(*[nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1) for _ in range(2)])\n",
        "#         self.trans_conv_1 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=3, stride=2)\n",
        "#         self.conv_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "#         self.trans_conv_2 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, stride=2)\n",
        "#         self.conv_3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1)\n",
        "#         self.trans_conv_3 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=3, stride=2)\n",
        "#         self.conv_4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1)\n",
        "#         self.pixelcnn_gated_block_1 = GatedBlock(in_channels=32, out_channels=32, kernel_size=(7, 7))\n",
        "#         self.pixelcnn_gated_blocks = nn.Sequential(*[GatedBlock(in_channels=32, out_channels=32, kernel_size=(5, 5)) for _ in range(gated_blocks)])\n",
        "#         self.pixelcnn_gate_1 = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ez43R_wnUosG"
      },
      "outputs": [],
      "source": [
        "class ConditionalDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim: int, in_channels: int=1, hidden_layers: int=5):\n",
        "        super(ConditionalDecoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.in_channels = in_channels\n",
        "        self.hidden_layers = hidden_layers\n",
        "\n",
        "        self.causal_block = CausalBlock(in_channels=in_channels, out_channels=latent_dim, kernel_size=7)\n",
        "        self.gated_blocks = nn.Sequential(\n",
        "            *[GatedBlock(in_channels=latent_dim, out_channels=latent_dim, kernel_size=5, latent_dim=latent_dim) for _ in range(hidden_layers)]\n",
        "        )\n",
        "        self.conv_1 = nn.Conv2d(in_channels=latent_dim, out_channels=2*latent_dim, kernel_size=(1, 1))\n",
        "        self.conditional_gate_1 = ConditionalGate(latent_dim=latent_dim, out_channels=latent_dim)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=latent_dim, out_channels=2*latent_dim, kernel_size=(1, 1))\n",
        "        self.conditional_gate_2 = ConditionalGate(latent_dim=latent_dim, out_channels=latent_dim)\n",
        "        self.conv_3 = nn.Conv2d(in_channels=latent_dim, out_channels=4*in_channels, kernel_size=(1, 1))\n",
        "\n",
        "    def forward(self, X, latent_var):\n",
        "        out_vertical, out_horizontal = self.causal_block(X)\n",
        "        out = self.gated_blocks({'in_vertical': out_vertical,\n",
        "                                 'in_horizontal': out_horizontal,\n",
        "                                 'latent': latent_var,\n",
        "                                 'skip': X.new_zeros(X.size()[0], self.latent_dim, X.size()[2], X.size()[3])})['in_horizontal']\n",
        "        out = self.conv_1(out)\n",
        "        out = self.conditional_gate_1(out, latent_var)\n",
        "        out = self.conv_2(out)\n",
        "        out = self.conditional_gate_2(out, latent_var)\n",
        "        out = self.conv_3(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RjIRY23PnwvE"
      },
      "outputs": [],
      "source": [
        "class PixelVAE(nn.Module):\n",
        "    def __init__(self, in_channels: int, latent_dim: int=32, hidden_layers: int=5):\n",
        "        super(PixelVAE, self).__init__()\n",
        "        self.encoder = Encoder(in_channels=in_channels,\n",
        "                               latent_dim=latent_dim)\n",
        "        self.decoder = ConditionalDecoder(latent_dim=latent_dim,\n",
        "                                          in_channels=in_channels,\n",
        "                                          hidden_layers=hidden_layers)\n",
        "\n",
        "    def sample(self, image_size: int, num_samples: int, device='cpu'):\n",
        "        self.eval()\n",
        "\n",
        "        H, W = image_size\n",
        "        C = self.decoder.in_channels\n",
        "\n",
        "        # 1) Sample z ~ N(0, I)\n",
        "        z = torch.randn(num_samples, self.encoder.latent_dim, device=device)\n",
        "\n",
        "        # 2) Initialize an empty canvas\n",
        "        samples = torch.zeros(num_samples, C, H, W, device=device)\n",
        "\n",
        "        # 3) Raster-scan over pixels: For each position (i, j) and each channel c, ask the decoder for the logits then sample.\n",
        "        with torch.inference_mode():\n",
        "            for i in range(H):\n",
        "                for j in range(W):\n",
        "                    # decoder expects (x_partial, z) and returns logits [B, C, H, W]\n",
        "                    logits = self.decoder(samples, z)\n",
        "                    probs = torch.softmax(logits[:, :, i, j], dim=1)\n",
        "                    sampled_pixel = torch.multinomial(probs, 1).squeeze(1)\n",
        "                    samples[:, 0, i, j] = sampled_pixel\n",
        "\n",
        "        return samples.cpu()\n",
        "\n",
        "    def forward(self, X):\n",
        "        mu, logvar, z = self.encoder(X)\n",
        "        out = self.decoder(X, z)\n",
        "        return mu, logvar, z, out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJnQbPKkX5M0",
        "outputId": "1cdd6f13-3f4f-46bc-f759-638759c06d82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 28, 28]), torch.Size([1, 16]), torch.Size([1, 4, 28, 28]))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @title Visualising forward passes and sampling of untrained model\n",
        "torch.manual_seed(42)\n",
        "model = PixelVAE(in_channels=1,\n",
        "                 latent_dim=16,\n",
        "                 hidden_layers=5)\n",
        "img, label = mnist_train[0]\n",
        "img = img.unsqueeze(0)\n",
        "img = torch.clamp((img * 4), max=3)\n",
        "sample_mu, sample_logvar, sample_z, sample_out = model(img)\n",
        "img.shape, sample_z.shape, sample_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPJkTdf01DUy",
        "outputId": "a657d795-2cea-4eb9-d526-8972bfcaaa99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), torch.Size([1, 1, 28, 28]))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "model = PixelVAE(in_channels=1,\n",
        "                 latent_dim=16,\n",
        "                 hidden_layers=5)\n",
        "img, label = mnist_train[0]\n",
        "sample = model.sample((28, 28), 1)\n",
        "img.shape, sample.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "HdXjDMpnu5UT",
        "outputId": "e23fc139-1b8c-4158-8ba5-ad4fbf628f96"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(sample.squeeze().detach().numpy(), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylHVgXJku-6k",
        "outputId": "8229cd4c-3038-4ca0-adcf-1256b254083b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JWTB-EOUv1mU"
      },
      "outputs": [],
      "source": [
        "# @title Creating DataLoader for binarised MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXy2P_oVv3LS",
        "outputId": "fea431a5-6fe3-4fa3-d2a2-bf4a574201cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:40<00:00,  8.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20 \n",
            "Recon: 0.46879093613624573, KL: 0.0018850988735755285, Total: 0.47067603500982125, Test loss: 0.2513661811146112\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/20 \n",
            "Recon: 0.2332124849319458, KL: 2.669207751750946e-06, Total: 0.23321515413969754, Test loss: 0.21893773111291587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/20 \n",
            "Recon: 0.21453307015101114, KL: 1.7120584845542908e-06, Total: 0.2145347822094957, Test loss: 0.20768943481361524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/20 \n",
            "Recon: 0.20662190883159637, KL: 1.4450783530871073e-06, Total: 0.20662335390994946, Test loss: 0.202397466181947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/20 \n",
            "Recon: 0.20196910343170166, KL: 1.327448586622874e-06, Total: 0.2019704308802883, Test loss: 0.1981589021012425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/20 \n",
            "Recon: 0.1984420038541158, KL: 1.258404552936554e-06, Total: 0.19844326225866873, Test loss: 0.1952050936679109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:40<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/20 \n",
            "Recon: 0.19549123338858287, KL: 1.2277722358703614e-06, Total: 0.19549246116081873, Test loss: 0.19280335530876733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/20 \n",
            "Recon: 0.19304008504549663, KL: 1.190457244714101e-06, Total: 0.19304127550274133, Test loss: 0.19060950676282754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/20 \n",
            "Recon: 0.19090788276195525, KL: 1.1659731467564901e-06, Total: 0.190909048735102, Test loss: 0.18803246076495503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/20 \n",
            "Recon: 0.18887510999043783, KL: 1.1461555957794189e-06, Total: 0.1888762561460336, Test loss: 0.18638535791311783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/20 \n",
            "Recon: 0.18704273737271626, KL: 1.129177212715149e-06, Total: 0.187043866549929, Test loss: 0.1852114600019333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/20 \n",
            "Recon: 0.18547341574033102, KL: 1.1116291085879008e-06, Total: 0.1854745273694396, Test loss: 0.18371865248527772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/20 \n",
            "Recon: 0.18407779653072356, KL: 1.1042277018229166e-06, Total: 0.1840789007584254, Test loss: 0.18197629769770102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/20 \n",
            "Recon: 0.18283889841238657, KL: 1.0840425888697307e-06, Total: 0.18283998245497546, Test loss: 0.1810512676977883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/20 \n",
            "Recon: 0.18171209883689882, KL: 1.0783106088638305e-06, Total: 0.18171317714750768, Test loss: 0.18016552091977847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:40<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/20 \n",
            "Recon: 0.18073283513387045, KL: 1.0657146573066712e-06, Total: 0.18073390084852775, Test loss: 0.17896763918498834\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/20 \n",
            "Recon: 0.17982728306452433, KL: 1.05980783700943e-06, Total: 0.17982834287236135, Test loss: 0.17829358720550903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/20 \n",
            "Recon: 0.17895832119782765, KL: 1.0495265324910483e-06, Total: 0.17895937072436016, Test loss: 0.17779624404998634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/20 \n",
            "Recon: 0.17826482648849487, KL: 1.0427782932917276e-06, Total: 0.17826586926678817, Test loss: 0.1769415905681281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [03:41<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/20 \n",
            "Recon: 0.17749319543043773, KL: 1.0268052419026694e-06, Total: 0.17749422223567962, Test loss: 0.17629774557515837\n"
          ]
        }
      ],
      "source": [
        "model = PixelVAE(in_channels=1,\n",
        "                 latent_dim=128,\n",
        "                 hidden_layers=15).to(device)\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimiser, step_size=10, gamma=0.5)\n",
        "epochs = 20\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimiser, max_lr=1e-4, total_steps=epochs*len(train_loader),\n",
        "    pct_start=0.1, anneal_strategy='cos', div_factor=10)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_reconstruction_loss, epoch_regularisation_loss = 0.0, 0.0\n",
        "\n",
        "    for imgs, _ in tqdm(train_loader):\n",
        "        imgs = imgs.to(device)\n",
        "\n",
        "        optimiser.zero_grad()\n",
        "\n",
        "        pixel_targets = torch.clamp((imgs * 4).long(), max=3)\n",
        "        mu, logvar, z, logits = model(pixel_targets.float())\n",
        "\n",
        "        # Reconstruction: sum over pixels, avg over batch\n",
        "        reconstruction_loss = F.cross_entropy(logits, pixel_targets.squeeze(1))\n",
        "\n",
        "        # KL divergence\n",
        "        regularisation_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1).mean()\n",
        "\n",
        "        loss = reconstruction_loss + regularisation_loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimiser.step()\n",
        "\n",
        "        epoch_reconstruction_loss += reconstruction_loss.item()\n",
        "        epoch_regularisation_loss += regularisation_loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    with torch.inference_mode():\n",
        "        for img, _ in test_loader:\n",
        "            img = img.to(device)\n",
        "            pixel_targets  = torch.clamp((img * 4).long(), max=3)   # (B,1,H,W)\n",
        "\n",
        "            mu, logvar, z, logits = model(pixel_targets.float())\n",
        "            loss = F.cross_entropy(logits, pixel_targets.squeeze(1))\n",
        "            running_val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = running_val_loss / len(test_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} \\nRecon: {epoch_reconstruction_loss/len(train_loader)}, \"\n",
        "          f\"KL: {epoch_regularisation_loss/len(train_loader)}, Total: {(epoch_reconstruction_loss+epoch_regularisation_loss)/len(train_loader)}, \"\n",
        "          f\"Test loss: {avg_val_loss}\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KmmFJDxxv5aM"
      },
      "outputs": [],
      "source": [
        "# Save trained model\n",
        "torch.save(model,'pixelvae_4_way_model_epochs_20_v3.pth')\n",
        "\n",
        "torch.save(optimiser,'pixelvae_4_way_optimiser_epochs_20_v3.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4ezR-Uov620",
        "outputId": "ab60b82a-4dd3-40bc-d6f9-129649133ec5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PixelVAE(\n",
              "  (encoder): Encoder(\n",
              "    (net): Sequential(\n",
              "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): ReLU()\n",
              "      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (7): ReLU()\n",
              "      (8): ZeroPad2d((0, 1, 0, 1))\n",
              "      (9): ReLU()\n",
              "      (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (11): ReLU()\n",
              "      (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (13): ReLU()\n",
              "      (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (15): ReLU()\n",
              "      (16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (17): ReLU()\n",
              "      (18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (19): ReLU()\n",
              "      (20): Flatten(start_dim=1, end_dim=-1)\n",
              "      (21): Linear(in_features=1024, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (decoder): ConditionalDecoder(\n",
              "    (causal_block): CausalBlock(\n",
              "      (vertical_fc): Conv2d(1, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (vertical_conv): CroppedConvolution2D(\n",
              "        (conv): Conv2d(1, 128, kernel_size=(4, 7), stride=(1, 1), padding=(4, 3))\n",
              "      )\n",
              "      (vertical_to_horizontal): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (horizontal_conv): MaskedConvolution2D(\n",
              "        (conv): Conv2d(1, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
              "      )\n",
              "      (horizontal_fc): MaskedConvolution2D(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (gated_blocks): Sequential(\n",
              "      (0): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (1): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (2): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (3): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (4): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (5): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (6): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (7): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (8): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (9): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (10): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (11): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (12): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (13): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "      (14): GatedBlock(\n",
              "        (vertical_fc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (vertical_to_horizontal): MaskedConvolution2D(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (vertical_conv): CroppedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(3, 2))\n",
              "        )\n",
              "        (horizontal_conv): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
              "        )\n",
              "        (horizontal_fc): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (horizontal_skip): MaskedConvolution2D(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (latent_embedding): Linear(in_features=64, out_features=128, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (conv_1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (conditional_gate_1): ConditionalGate(\n",
              "      (latent_embedding_tanh): Linear(in_features=64, out_features=64, bias=True)\n",
              "      (latent_embedding_sigmoid): Linear(in_features=64, out_features=64, bias=True)\n",
              "    )\n",
              "    (conv_2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (conditional_gate_2): ConditionalGate(\n",
              "      (latent_embedding_tanh): Linear(in_features=64, out_features=64, bias=True)\n",
              "      (latent_embedding_sigmoid): Linear(in_features=64, out_features=64, bias=True)\n",
              "    )\n",
              "    (conv_3): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @title Load trained model\n",
        "\n",
        "model = PixelVAE(in_channels=1,\n",
        "                 latent_dim=64,\n",
        "                 hidden_layers=15)  # Create an instance of your model\n",
        "\n",
        "model.load_state_dict(torch.load('pixelvae_4_way_model_epochs_5.pth', weights_only=False)) # Load the saved state dictionary\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o1sxhRO7v9KO"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x1200 with 100 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "generated_images = model.sample((28, 28), num_samples=100, device=device)\n",
        "\n",
        "# Plot the 100 images in a 10x10 grid\n",
        "fig, axes = plt.subplots(10, 10, figsize=(12, 12))\n",
        "for idx, ax in enumerate(axes.flatten()):\n",
        "    ax.imshow(generated_images[idx].squeeze(), cmap='gray')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rinm4mT5v-58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average NLL (nats per pixel): 0.17632228683160275\n",
            "Bits per dim: 0.2543792888101547\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def compute_bits_per_dim(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_elements = 0\n",
        "    with torch.inference_mode():\n",
        "        for imgs, _ in data_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            pixel_targets = torch.clamp((imgs * 4).long(), max=3)\n",
        "            batch_size = imgs.shape[0]\n",
        "            \n",
        "            num_pixels = imgs.shape[2] * imgs.shape[3]\n",
        "            mu, logvar, z, output = model(pixel_targets.float())\n",
        "            \n",
        "            loss = F.cross_entropy(output, pixel_targets.squeeze(1), reduction='sum')\n",
        "            total_loss += loss.item()\n",
        "            total_elements += batch_size * num_pixels\n",
        "\n",
        "    \n",
        "    average_nll = total_loss / total_elements\n",
        "    \n",
        "    bits_per_dim = average_nll / math.log(2)\n",
        "    return average_nll, bits_per_dim\n",
        "\n",
        "average_nll, bits_dim = compute_bits_per_dim(model, test_loader, device)\n",
        "print(f\"Average NLL (nats per pixel): {average_nll}\")\n",
        "print(f\"Bits per dim: {bits_dim}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
